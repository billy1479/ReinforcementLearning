{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTNU1mwGB1ZD"
   },
   "source": [
    "**Dependencies and imports**\n",
    "\n",
    "This can take a minute..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install swig\n",
    "# !pip install --upgrade rldurham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import rldurham as rld\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJHtclV_30Re"
   },
   "source": [
    "## Reinforcement Learning set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4jXNHP8_U-rn"
   },
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=256):\n",
    "        super(Agent, self).__init__()\n",
    "        \n",
    "        # Initialize networks with orthogonal weights for better gradient flow\n",
    "        self.policy = self._build_policy_network(state_dim, action_dim, hidden_dim)\n",
    "        self.value = self._build_value_network(state_dim, hidden_dim)\n",
    "        \n",
    "        # Hyperparameters tuned for stability\n",
    "        self.gamma = 0.99\n",
    "        self.learning_rate = 3e-4 #4e-4 was good\n",
    "        self.gae_lambda = 0.95\n",
    "        self.clip_ratio = 0.2\n",
    "        self.entropy_coef = 0.01  # Encourage exploration\n",
    "        self.value_coef = 0.5    # Balance value and policy learning\n",
    "        \n",
    "        # Adaptive noise control\n",
    "        self.init_action_std = 0.6\n",
    "        self.action_std = self.init_action_std\n",
    "        self.action_std_decay = 0.999\n",
    "        self.min_action_std = 0.2\n",
    "        self.noise_decay_start = 1000  # Start decay after 100 episodes # 500 was good\n",
    "        \n",
    "        # Experience management\n",
    "        self.trajectory = []\n",
    "        self.experience_buffer = []  # Store successful episodes\n",
    "        self.buffer_size = 10000     # Maximum buffer size\n",
    "        self.success_threshold = 50  # Threshold to consider an episode \"successful\"\n",
    "        self.replay_ratio = 0.3  \n",
    "        \n",
    "        self.value_normalizer = RunningMeanStd()\n",
    "        self.state_normalizer = RunningMeanStd(shape=state_dim)\n",
    "        self.reward_normalizer = RunningMeanStd()\n",
    "        \n",
    "        # Optimization\n",
    "        self.policy_optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        self.value_optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        self.snapshot_interval = 100  # Save model snapshot every N episodes\n",
    "        self.snapshots = []\n",
    "        self.max_snapshots = 3\n",
    "        self.snapshot_weights = [0.7, 0.2, 0.1]  # Weights for ensemble predictions\n",
    "        \n",
    "        # Statistics tracking\n",
    "        self.running_rewards = deque(maxlen=100)\n",
    "        self.early_stopping_patience = 50\n",
    "        self.patience_counter = 0\n",
    "        self.episode_count = 0\n",
    "        self.best_reward = float('-inf')\n",
    "        self.best_avg_reward = float('-inf')\n",
    "        self.recent_actions = deque(maxlen=5)  # For action smoothing\n",
    "        \n",
    "    def _build_policy_network(self, state_dim, action_dim, hidden_dim):\n",
    "        \"\"\"Build policy network with proper initialization\"\"\"\n",
    "        policy = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, action_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Orthogonal initialization for better training dynamics\n",
    "        for layer in policy:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                torch.nn.init.orthogonal_(layer.weight, gain=np.sqrt(2))\n",
    "                torch.nn.init.zeros_(layer.bias)\n",
    "        \n",
    "        return policy\n",
    "    \n",
    "    def _build_value_network(self, state_dim, hidden_dim):\n",
    "        \"\"\"Build value network with proper initialization\"\"\"\n",
    "        value = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "        for layer in value:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                torch.nn.init.orthogonal_(layer.weight, gain=np.sqrt(2))\n",
    "                torch.nn.init.zeros_(layer.bias)\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def normalize_state(self, state):\n",
    "        \"\"\"Normalize state using running statistics\"\"\"\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = torch.FloatTensor(state)\n",
    "        return torch.FloatTensor(self.state_normalizer(state.numpy()))\n",
    "    \n",
    "    def normalize_reward(self, reward):\n",
    "        \"\"\"Normalize rewards for more stable learning\"\"\"\n",
    "        self.reward_normalizer(np.array([reward]))\n",
    "        return reward\n",
    "    \n",
    "    def sample_action(self, state, deterministic=False):\n",
    "        \"\"\"Sample action with adaptive noise and temporal smoothing\"\"\"\n",
    "        state = self.normalize_state(state)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            mean_action = self.policy(state)\n",
    "            \n",
    "            if deterministic:\n",
    "                action = mean_action\n",
    "            else:\n",
    "                # Add exploration noise with adaptive standard deviation\n",
    "                noise = torch.randn_like(mean_action) * self.action_std\n",
    "                action = torch.clamp(mean_action + noise, -1, 1)\n",
    "                \n",
    "                # Apply temporal smoothing for more natural movements\n",
    "                if len(self.recent_actions) > 0:\n",
    "                    smooth_factor = 0.7\n",
    "                    prev_action = np.mean([a for a in self.recent_actions], axis=0)\n",
    "                    action = smooth_factor * action + (1 - smooth_factor) * torch.FloatTensor(prev_action)\n",
    "                \n",
    "                # Ensemble prediction from snapshots for more robustness\n",
    "                if len(self.snapshots) > 0 and np.random.random() < 0.3:  # 30% chance to use ensemble\n",
    "                    ensemble_actions = [snapshot_policy(state) for snapshot_policy, _ in self.snapshots]\n",
    "                    ensemble_actions.append(action)  # Include current policy\n",
    "                    \n",
    "                    # Weight the actions based on recency\n",
    "                    weights = self.snapshot_weights[:len(self.snapshots)] + [1.0]\n",
    "                    weights = [w/sum(weights) for w in weights]\n",
    "                    \n",
    "                    action = sum(w * a for w, a in zip(weights, ensemble_actions))\n",
    "                    action = torch.clamp(action, -1, 1)\n",
    "            \n",
    "            self.recent_actions.append(action.numpy())\n",
    "        \n",
    "        return action.numpy()\n",
    "    \n",
    "    def put_data(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Store transition with normalized states\"\"\"\n",
    "        state = self.normalize_state(state)\n",
    "        next_state = self.normalize_state(next_state)\n",
    "        norm_reward = self.normalize_reward(reward)\n",
    "        self.trajectory.append((state, action, norm_reward, next_state, done))\n",
    "    \n",
    "    def add_to_experience_buffer(self, episode_data, episode_reward):\n",
    "        \"\"\"Add successful episodes to the experience buffer\"\"\"\n",
    "        if episode_reward > self.success_threshold:\n",
    "            self.experience_buffer.extend(episode_data)\n",
    "            # Trim buffer if it gets too large\n",
    "            if len(self.experience_buffer) > self.buffer_size:\n",
    "                excess = len(self.experience_buffer) - self.buffer_size\n",
    "                self.experience_buffer = self.experience_buffer[excess:]\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Update policy and value networks with improved stability measures\"\"\"\n",
    "        if len(self.trajectory) < 1:\n",
    "            return 0, 0\n",
    "        \n",
    "        # Check if we should add the trajectory to the experience buffer\n",
    "        episode_reward = sum([r for _, _, r, _, _ in self.trajectory])\n",
    "        self.add_to_experience_buffer(self.trajectory, episode_reward)\n",
    "        \n",
    "        # Mix in some past successful experiences if available\n",
    "        if len(self.experience_buffer) > 0 and np.random.random() < self.replay_ratio:\n",
    "            replay_size = min(len(self.experience_buffer), int(len(self.trajectory) * 0.5))\n",
    "            replay_samples = random.sample(self.experience_buffer, replay_size)\n",
    "            training_data = self.trajectory + replay_samples\n",
    "        else:\n",
    "            training_data = self.trajectory\n",
    "        \n",
    "        states, actions, rewards, next_states, dones = zip(*training_data)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        states = torch.stack(states)\n",
    "        actions = torch.FloatTensor(actions)\n",
    "        rewards = torch.FloatTensor(rewards)\n",
    "        next_states = torch.stack(next_states)\n",
    "        dones = torch.FloatTensor(dones)\n",
    "        \n",
    "        # Compute normalized returns and advantages\n",
    "        with torch.no_grad():\n",
    "            values = self.value(states).squeeze()\n",
    "            next_values = self.value(next_states).squeeze()\n",
    "            \n",
    "            # Compute GAE\n",
    "            advantages = torch.zeros_like(rewards)\n",
    "            gae = 0\n",
    "            for t in reversed(range(len(rewards))):\n",
    "                if t == len(rewards) - 1:\n",
    "                    next_value = next_values[t]\n",
    "                else:\n",
    "                    next_value = values[t + 1]\n",
    "                \n",
    "                delta = rewards[t] + self.gamma * next_value * (1 - dones[t]) - values[t]\n",
    "                gae = delta + self.gamma * self.gae_lambda * (1 - dones[t]) * gae\n",
    "                advantages[t] = gae\n",
    "            \n",
    "            returns = advantages + values\n",
    "            \n",
    "            # Normalize advantages\n",
    "            advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "        \n",
    "        # Compute action probabilities\n",
    "        mean_actions = self.policy(states)\n",
    "        dist = torch.distributions.Normal(mean_actions, self.action_std)\n",
    "        old_log_probs = dist.log_prob(actions).sum(dim=1)\n",
    "        \n",
    "        # Multiple epochs of optimization with early stopping\n",
    "        policy_losses = []\n",
    "        value_losses = []\n",
    "        kl_divs = []\n",
    "        \n",
    "        for epoch in range(10):  # 10 epochs max\n",
    "            # Compute new action probabilities\n",
    "            mean_actions = self.policy(states)\n",
    "            dist = torch.distributions.Normal(mean_actions, self.action_std)\n",
    "            new_log_probs = dist.log_prob(actions).sum(dim=1)\n",
    "            \n",
    "            # Compute entropy for exploration\n",
    "            entropy = dist.entropy().mean()\n",
    "            \n",
    "            # Compute policy loss with clipping\n",
    "            ratio = torch.exp(new_log_probs - old_log_probs.detach())\n",
    "            surr1 = ratio * advantages\n",
    "            surr2 = torch.clamp(ratio, 1 - self.clip_ratio, 1 + self.clip_ratio) * advantages\n",
    "            policy_loss = -torch.min(surr1, surr2).mean()\n",
    "            \n",
    "            # Compute value loss with clipping\n",
    "            value_pred = self.value(states).squeeze()\n",
    "            value_clipped = values + torch.clamp(value_pred - values, -self.clip_ratio, self.clip_ratio)\n",
    "            value_loss_1 = F.mse_loss(value_pred, returns.detach())\n",
    "            value_loss_2 = F.mse_loss(value_clipped, returns.detach())\n",
    "            value_loss = torch.max(value_loss_1, value_loss_2)\n",
    "            \n",
    "            # Compute KL divergence for early stopping\n",
    "            approx_kl = ((old_log_probs - new_log_probs) * ratio).mean().item()\n",
    "            kl_divs.append(approx_kl)\n",
    "            \n",
    "            # Store losses\n",
    "            policy_losses.append(policy_loss.item())\n",
    "            value_losses.append(value_loss.item())\n",
    "            \n",
    "            # Early stopping based on KL divergence\n",
    "            if approx_kl > 0.015:\n",
    "                break\n",
    "                \n",
    "            # Update policy network\n",
    "            self.policy_optimizer.zero_grad()\n",
    "            policy_loss_with_entropy = policy_loss - self.entropy_coef * entropy\n",
    "            policy_loss_with_entropy.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.policy.parameters(), max_norm=0.5)\n",
    "            self.policy_optimizer.step()\n",
    "            \n",
    "            # Update value network separately for more stability\n",
    "            self.value_optimizer.zero_grad()\n",
    "            (self.value_coef * value_loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.value.parameters(), max_norm=0.5)\n",
    "            self.value_optimizer.step()\n",
    "        \n",
    "        # Clear trajectory buffer\n",
    "        self.trajectory = []\n",
    "        \n",
    "        # Update exploration noise\n",
    "        if self.episode_count > self.noise_decay_start:\n",
    "            self.action_std = max(self.min_action_std, \n",
    "                                self.action_std * self.action_std_decay)\n",
    "        \n",
    "        return np.mean(policy_losses), np.mean(value_losses)\n",
    "    \n",
    "    def update_stats(self, episode_reward):\n",
    "        \"\"\"Update running statistics and episode count\"\"\"\n",
    "        self.running_rewards.append(episode_reward)\n",
    "        self.episode_count += 1\n",
    "        self.best_reward = max(self.best_reward, episode_reward)\n",
    "        \n",
    "        # Early stopping check\n",
    "        current_avg_reward = self.get_average_reward()\n",
    "        if current_avg_reward > self.best_avg_reward:\n",
    "            self.best_avg_reward = current_avg_reward\n",
    "            self.patience_counter = 0\n",
    "            \n",
    "            # Save model snapshot for ensemble\n",
    "            if self.episode_count % self.snapshot_interval == 0:\n",
    "                policy_copy = copy.deepcopy(self.policy)\n",
    "                value_copy = copy.deepcopy(self.value)\n",
    "                self.snapshots.append((policy_copy, value_copy))\n",
    "                if len(self.snapshots) > self.max_snapshots:\n",
    "                    self.snapshots.pop(0)  # Remove oldest snapshot\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "            \n",
    "            # If patience exceeded, revert to best snapshot\n",
    "            if self.patience_counter >= self.early_stopping_patience and len(self.snapshots) > 0:\n",
    "                print(f\"Performance plateaued for {self.early_stopping_patience} episodes. Reverting to previous best model.\")\n",
    "                latest_snapshot = self.snapshots[-1]\n",
    "                self.policy = copy.deepcopy(latest_snapshot[0])\n",
    "                self.value = copy.deepcopy(latest_snapshot[1])\n",
    "                self.patience_counter = 0\n",
    "    \n",
    "    def get_average_reward(self):\n",
    "        \"\"\"Calculate average reward over last 100 episodes\"\"\"\n",
    "        return np.mean(self.running_rewards) if self.running_rewards else 0\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset temporal smoothing between episodes\"\"\"\n",
    "        self.recent_actions.clear()\n",
    "        \n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        Save model state with enhanced security and compatibility.\n",
    "        This version handles separate optimizers for policy and value networks.\n",
    "        \"\"\"\n",
    "        # Save neural network states and their optimizers separately\n",
    "        network_state = {\n",
    "            'policy_state_dict': self.policy.state_dict(),\n",
    "            'value_state_dict': self.value.state_dict(),\n",
    "            'policy_optimizer_state_dict': self.policy_optimizer.state_dict(),\n",
    "            'value_optimizer_state_dict': self.value_optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(network_state, filename + '_networks.pt')\n",
    "        \n",
    "        # Save normalizer statistics as plain numbers\n",
    "        normalizer_state = {\n",
    "            'state_mean': self.state_normalizer.mean.tolist(),\n",
    "            'state_var': self.state_normalizer.var.tolist(),\n",
    "            'state_count': float(self.state_normalizer.count),\n",
    "            'value_mean': self.value_normalizer.mean.tolist(),\n",
    "            'value_var': self.value_normalizer.var.tolist(),\n",
    "            'value_count': float(self.value_normalizer.count),\n",
    "        }\n",
    "        \n",
    "        # Save other parameters\n",
    "        other_state = {\n",
    "            'episode_count': self.episode_count,\n",
    "            'best_reward': float(self.best_reward),\n",
    "            'action_std': float(self.action_std),\n",
    "            'normalizer_state': normalizer_state\n",
    "        }\n",
    "        \n",
    "        # Save as JSON for better compatibility\n",
    "        with open(filename + '_other.json', 'w') as f:\n",
    "            json.dump(other_state, f)\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\"\n",
    "        Load model state with enhanced security and compatibility.\n",
    "        This version handles separate optimizers for policy and value networks.\n",
    "        \"\"\"\n",
    "        # Load neural network states\n",
    "        network_state = torch.load(filename + '_networks.pt', weights_only=True)\n",
    "        self.policy.load_state_dict(network_state['policy_state_dict'])\n",
    "        self.value.load_state_dict(network_state['value_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(network_state['policy_optimizer_state_dict'])\n",
    "        self.value_optimizer.load_state_dict(network_state['value_optimizer_state_dict'])\n",
    "        \n",
    "        # Load other parameters from JSON\n",
    "        try:\n",
    "            with open(filename + '_other.json', 'r') as f:\n",
    "                other_state = json.load(f)\n",
    "                \n",
    "            # Restore normalizer states\n",
    "            normalizer_state = other_state['normalizer_state']\n",
    "            \n",
    "            # Reconstruct state normalizer\n",
    "            self.state_normalizer.mean = np.array(normalizer_state['state_mean'], dtype=np.float32)\n",
    "            self.state_normalizer.var = np.array(normalizer_state['state_var'], dtype=np.float32)\n",
    "            self.state_normalizer.count = normalizer_state['state_count']\n",
    "            \n",
    "            # Reconstruct value normalizer\n",
    "            self.value_normalizer.mean = np.array(normalizer_state['value_mean'], dtype=np.float32)\n",
    "            self.value_normalizer.var = np.array(normalizer_state['value_var'], dtype=np.float32)\n",
    "            self.value_normalizer.count = normalizer_state['value_count']\n",
    "            \n",
    "            # Restore other parameters\n",
    "            self.episode_count = other_state['episode_count']\n",
    "            self.best_reward = other_state['best_reward']\n",
    "            self.action_std = other_state['action_std']\n",
    "            \n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "            print(f\"Warning: Could not load complete state. Only network weights were restored. Error: {e}\")\n",
    "\n",
    "class RunningMeanStd:\n",
    "    \"\"\"Tracks running mean and standard deviation for normalization\"\"\"\n",
    "    def __init__(self, shape=(), epsilon=1e-4):\n",
    "        self.mean = np.zeros(shape, dtype=np.float32)\n",
    "        self.var = np.ones(shape, dtype=np.float32)\n",
    "        self.count = epsilon\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        batch_mean = np.mean(x, axis=0)\n",
    "        batch_var = np.var(x, axis=0)\n",
    "        batch_count = x.shape[0] if len(x.shape) > 1 else 1\n",
    "        \n",
    "        delta = batch_mean - self.mean\n",
    "        self.mean += delta * batch_count / (self.count + batch_count)\n",
    "        m_a = self.var * self.count\n",
    "        m_b = batch_var * batch_count\n",
    "        M2 = m_a + m_b + np.square(delta) * self.count * batch_count / (self.count + batch_count)\n",
    "        self.var = M2 / (self.count + batch_count)\n",
    "        self.count += batch_count\n",
    "        \n",
    "        return (x - self.mean) / np.sqrt(self.var + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEv4ZjXmyrHo"
   },
   "source": [
    "### Prepare the environment and wrap it to capture statistics, logs, and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1Xrcek4hxDXl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is: cpu (as recommended)\n",
      "actions are continuous with 4 dimensions/#actions\n",
      "observations are continuous with 24 dimensions/#observations\n",
      "maximum timesteps is: None\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = rld.make(\"rldurham/Walker\", render_mode=\"rgb_array\")\n",
    "# env = rld.make(\"rldurham/Walker\", render_mode=\"rgb_array\", hardcore=True) # only attempt this when your agent has solved the non-hardcore version\n",
    "\n",
    "# get statistics, logs, and videos\n",
    "env = rld.Recorder(\n",
    "    env,\n",
    "    smoothing=10,                       # track rolling averages (useful for plotting)\n",
    "    video=True,                         # enable recording videos\n",
    "    video_folder=\"videos\",              # folder for videos\n",
    "    video_prefix=\"nkfn77-agent-video\",  # prefix for videos (replace xxxx00 with your username)\n",
    "    logs=True,                          # keep logs\n",
    ")\n",
    "\n",
    "# training on CPU recommended\n",
    "rld.check_device()\n",
    "\n",
    "# environment info\n",
    "discrete_act, discrete_obs, act_dim, obs_dim = rld.env_info(env, print_out=True)\n",
    "\n",
    "# render start image\n",
    "env.reset(seed=42)\n",
    "rld.render(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at episode 10000\n",
      "Running evaluation at episode 10000...\n",
      "Evaluation complete - Avg reward over 5 episodes: 220.72\n",
      "Training completed in 267.32 minutes\n",
      "Best average reward: 193.69\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_avg_reward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 394\u001b[0m\n\u001b[1;32m    386\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Save final metrics summary as JSON\u001b[39;00m\n\u001b[1;32m    389\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_episodes\u001b[39m\u001b[38;5;124m'\u001b[39m: episode \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_episodes\u001b[39m\u001b[38;5;124m'\u001b[39m: max_episodes,\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_stopped\u001b[39m\u001b[38;5;124m'\u001b[39m: patience_counter \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m early_stop_patience,\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_duration_seconds\u001b[39m\u001b[38;5;124m'\u001b[39m: time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time,\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_avg_reward\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mfinal_avg_reward\u001b[49m,\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_avg_reward\u001b[39m\u001b[38;5;124m'\u001b[39m: best_avg_reward,\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: agent\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_action_std\u001b[39m\u001b[38;5;124m'\u001b[39m: agent\u001b[38;5;241m.\u001b[39maction_std,\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_path\u001b[39m\u001b[38;5;124m'\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model_path\u001b[39m\u001b[38;5;124m'\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_checkpoint_ep\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    401\u001b[0m }\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(metrics_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_summary.json\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    404\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(summary, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_avg_reward' is not defined"
     ]
    }
   ],
   "source": [
    "# in the submission please use seed_everything with seed 42 for verification\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Ensure reproducibility across runs\n",
    "seed, observation, info = rld.seed_everything(42, env)\n",
    "\n",
    "# Initialize agent\n",
    "agent = Agent(env.observation_space.shape[0], env.action_space.shape[0])\n",
    "max_episodes = 10000\n",
    "max_timesteps = 2000\n",
    "\n",
    "# Track statistics for plotting with enhanced metrics\n",
    "tracker = rld.InfoTracker()\n",
    "evaluation_interval = 50  # Evaluate agent without exploration every N episodes\n",
    "checkpoint_interval = 500  # Save model checkpoint every N episodes\n",
    "early_stop_patience = 200  # Episodes to wait before early stopping\n",
    "best_avg_reward = float('-inf')\n",
    "patience_counter = 0\n",
    "min_episodes_before_early_stop = 1000  # Minimum training episodes before considering early stopping\n",
    "\n",
    "# Create directories for checkpoints and metrics\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "metrics_dir = \"metrics\"\n",
    "plots_dir = os.path.join(metrics_dir, \"plots\")\n",
    "csv_dir = os.path.join(metrics_dir, \"csv\")\n",
    "video_dir = os.path.join(metrics_dir, \"videos\")\n",
    "\n",
    "# Create all necessary directories\n",
    "for directory in [checkpoint_dir, metrics_dir, plots_dir, csv_dir, video_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Configure video path if the environment supports it\n",
    "try:\n",
    "    env.set_video_path(video_dir)\n",
    "except:\n",
    "    print(f\"Environment doesn't support custom video paths. Videos may be saved elsewhere.\")\n",
    "\n",
    "# Initialize training metrics tracking\n",
    "training_stats = {\n",
    "    'episode_rewards': [],\n",
    "    'avg_rewards': [],\n",
    "    'policy_losses': [],\n",
    "    'value_losses': [],\n",
    "    'episode_lengths': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "# Vectorize environment operations if possible\n",
    "# Note: This is a placeholder - actual implementation depends on the env type\n",
    "try:\n",
    "    env = rld.make_env_faster(env)  # Fictional function - replace with actual vectorization if available\n",
    "except:\n",
    "    print(\"Environment vectorization not available, using standard environment\")\n",
    "\n",
    "# Learning rate scheduler for gradual LR reduction\n",
    "initial_lr = agent.learning_rate\n",
    "min_lr = initial_lr / 10\n",
    "lr_decay_factor = 0.999\n",
    "lr_decay_start = 1000\n",
    "\n",
    "# Start training timer\n",
    "start_time = time.time()\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    # Set up episode - only record video occasionally to save time\n",
    "    is_evaluation_episode = episode % evaluation_interval == 0\n",
    "    env.info = episode % 10 == 0\n",
    "    env.video = episode % 250 == 0  # Reduced frequency for video recording\n",
    "    \n",
    "    current_observation, info = env.reset()\n",
    "    episode_reward = 0\n",
    "    episode_start_time = time.time()\n",
    "    \n",
    "    # Reset agent's temporal smoothing\n",
    "    agent.reset()\n",
    "    \n",
    "    # Store transitions for batch processing\n",
    "    episode_transitions = []\n",
    "    \n",
    "    # Run episode\n",
    "    for t in range(max_timesteps):\n",
    "        # Get action from agent (deterministic for evaluation episodes)\n",
    "        action = agent.sample_action(current_observation, deterministic=is_evaluation_episode)\n",
    "        \n",
    "        # Take step in environment\n",
    "        next_observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        # Store transition\n",
    "        if not is_evaluation_episode:  # Don't store evaluation episodes\n",
    "            agent.put_data(current_observation, action, reward, next_observation, \n",
    "                          terminated or truncated)\n",
    "        \n",
    "        episode_reward += reward\n",
    "        episode_transitions.append((current_observation, action, reward, next_observation, \n",
    "                                   terminated or truncated))\n",
    "        \n",
    "        # Update observation\n",
    "        current_observation = next_observation\n",
    "        \n",
    "        # Check if episode is done\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    \n",
    "    # Only update the agent if this wasn't an evaluation episode\n",
    "    if not is_evaluation_episode:\n",
    "        # Update learning rate according to schedule\n",
    "        if episode > lr_decay_start:\n",
    "            new_lr = max(min_lr, initial_lr * (lr_decay_factor ** (episode - lr_decay_start)))\n",
    "            for param_group in agent.policy_optimizer.param_groups:\n",
    "                param_group['lr'] = new_lr\n",
    "            for param_group in agent.value_optimizer.param_groups:\n",
    "                param_group['lr'] = new_lr\n",
    "            agent.learning_rate = new_lr\n",
    "            \n",
    "        # Train agent in batches (more efficient)\n",
    "        policy_loss, value_loss = agent.train()\n",
    "    else:\n",
    "        policy_loss, value_loss = 0, 0  # No training during evaluation\n",
    "    \n",
    "    # Update agent statistics\n",
    "    agent.update_stats(episode_reward)\n",
    "    \n",
    "    # Save metrics\n",
    "    episode_length = t + 1\n",
    "    training_stats['episode_rewards'].append(episode_reward)\n",
    "    training_stats['avg_rewards'].append(agent.get_average_reward())\n",
    "    training_stats['policy_losses'].append(policy_loss)\n",
    "    training_stats['value_losses'].append(value_loss)\n",
    "    training_stats['episode_lengths'].append(episode_length)\n",
    "    training_stats['learning_rates'].append(agent.learning_rate)\n",
    "    \n",
    "    # Save metrics to CSV after each episode\n",
    "    # if episode == 0:\n",
    "    #     # Create CSV files with headers\n",
    "    #     metrics_files = {\n",
    "    #         'rewards': os.path.join(csv_dir, 'episode_rewards.csv'),\n",
    "    #         'avg_rewards': os.path.join(csv_dir, 'avg_rewards.csv'),\n",
    "    #         'losses': os.path.join(csv_dir, 'losses.csv'),\n",
    "    #         'episode_data': os.path.join(csv_dir, 'episode_data.csv')\n",
    "    #     }\n",
    "        \n",
    "    #     # Initialize CSV files with headers\n",
    "    #     with open(metrics_files['rewards'], 'w') as f:\n",
    "    #         f.write('episode,reward\\n')\n",
    "        \n",
    "    #     with open(metrics_files['avg_rewards'], 'w') as f:\n",
    "    #         f.write('episode,avg_reward_last_100\\n')\n",
    "            \n",
    "    #     with open(metrics_files['losses'], 'w') as f:\n",
    "    #         f.write('episode,policy_loss,value_loss\\n')\n",
    "            \n",
    "    #     with open(metrics_files['episode_data'], 'w') as f:\n",
    "    #         f.write('episode,length,learning_rate,action_std\\n')\n",
    "    \n",
    "    # Append data to CSV files\n",
    "    # with open(os.path.join(csv_dir, 'episode_rewards.csv'), 'a') as f:\n",
    "    #     f.write(f\"{episode},{episode_reward}\\n\")\n",
    "        \n",
    "    # with open(os.path.join(csv_dir, 'avg_rewards.csv'), 'a') as f:\n",
    "    #     f.write(f\"{episode},{agent.get_average_reward()}\\n\")\n",
    "        \n",
    "    # with open(os.path.join(csv_dir, 'losses.csv'), 'a') as f:\n",
    "    #     f.write(f\"{episode},{policy_loss},{value_loss}\\n\")\n",
    "        \n",
    "    # with open(os.path.join(csv_dir, 'episode_data.csv'), 'a') as f:\n",
    "    #     f.write(f\"{episode},{episode_length},{agent.learning_rate},{agent.action_std}\\n\")\n",
    "    \n",
    "    # Print progress with more detailed information\n",
    "    if episode % 10 == 0:\n",
    "        avg_reward = agent.get_average_reward()\n",
    "        elapsed_time = time.time() - start_time\n",
    "        eps_per_second = (episode + 1) / elapsed_time if elapsed_time > 0 else 0\n",
    "        estimated_remaining = (max_episodes - episode - 1) / eps_per_second / 60 if eps_per_second > 0 else 0\n",
    "        \n",
    "        print(f\"Episode {episode+1}/{max_episodes}, Reward: {episode_reward:.2f}, \"\n",
    "              f\"Avg Reward: {avg_reward:.2f}, Action STD: {agent.action_std:.3f}, \"\n",
    "              f\"Episode Length: {episode_length}, Time: {elapsed_time:.1f}s, \"\n",
    "              f\"Est. Remaining: {estimated_remaining:.1f}min\")\n",
    "    \n",
    "    # Track and plot\n",
    "    tracker.track(info)\n",
    "    if (episode + 1) % 10 == 0:\n",
    "        tracker.plot(r_mean_=True, r_std_=True, r_sum=dict(linestyle=':', marker='x'))\n",
    "        \n",
    "        # Add additional plots for training metrics\n",
    "        # Create plot filename with timestamp for easier organization\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        plot_filename = os.path.join(plots_dir, f\"metrics_ep{episode+1}_{timestamp}.png\")\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.plot(training_stats['episode_rewards'][-100:])\n",
    "        plt.title('Recent Episode Rewards')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Reward')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.plot(training_stats['policy_losses'][-100:], label='Policy Loss')\n",
    "        plt.plot(training_stats['value_losses'][-100:], label='Value Loss')\n",
    "        plt.title('Losses')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.plot(training_stats['episode_lengths'][-100:])\n",
    "        plt.title('Episode Lengths')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Steps')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.plot(training_stats['learning_rates'])\n",
    "        plt.title('Learning Rate')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('LR')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(2, 3, 5)\n",
    "        # Moving average of rewards for smoothed trend\n",
    "        window_size = min(25, len(training_stats['episode_rewards']))\n",
    "        if window_size > 1:\n",
    "            smoothed_rewards = np.convolve(\n",
    "                training_stats['episode_rewards'], \n",
    "                np.ones(window_size)/window_size, \n",
    "                mode='valid'\n",
    "            )\n",
    "            plt.plot(smoothed_rewards)\n",
    "            plt.title(f'Smoothed Rewards (window={window_size})')\n",
    "            plt.xlabel('Episode')\n",
    "            plt.ylabel('Smoothed Reward')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(2, 3, 6)\n",
    "        # Compare action standard deviation with episode rewards\n",
    "        recent_episodes = min(100, len(training_stats['episode_rewards']))\n",
    "        if recent_episodes > 0:\n",
    "            episodes_x = list(range(len(training_stats['episode_rewards'])))[-recent_episodes:]\n",
    "            ax1 = plt.gca()\n",
    "            ax1.set_xlabel('Episode')\n",
    "            ax1.set_ylabel('Reward', color='tab:blue')\n",
    "            ax1.plot(episodes_x, training_stats['episode_rewards'][-recent_episodes:], color='tab:blue')\n",
    "            ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Create second y-axis for action std\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.set_ylabel('Action STD', color='tab:red')\n",
    "            ax2.plot([agent.action_std] * recent_episodes, color='tab:red', linestyle='--')\n",
    "            ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "            plt.title('Reward vs. Exploration (Action STD)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_filename, dpi=300)  # Higher DPI for better quality\n",
    "        \n",
    "        # Also save a copy as the \"latest\" plot for easy access\n",
    "        plt.savefig(os.path.join(plots_dir, f\"latest_metrics.png\"), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if (episode + 1) % checkpoint_interval == 0 or episode == max_episodes - 1:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"agent_checkpoint_ep{episode+1}\")\n",
    "        agent.save(checkpoint_path)\n",
    "        print(f\"Checkpoint saved at episode {episode+1}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    curr_avg_reward = agent.get_average_reward()\n",
    "    if episode > min_episodes_before_early_stop:\n",
    "        if curr_avg_reward > best_avg_reward:\n",
    "            best_avg_reward = curr_avg_reward\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            best_model_path = os.path.join(checkpoint_dir, \"agent_best\")\n",
    "            agent.save(best_model_path)\n",
    "            print(f\"New best model saved with avg reward: {best_avg_reward:.2f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        # Check if we should stop early - UNCOMMENTED TO AVOID EARLY STOPPING\n",
    "        # if patience_counter >= early_stop_patience:\n",
    "        #     print(f\"Early stopping triggered after {episode+1} episodes\")\n",
    "        #     print(f\"Loading best model with avg reward: {best_avg_reward:.2f}\")\n",
    "        #     agent.load(best_model_path)\n",
    "        #     break\n",
    "    \n",
    "    # Periodically run evaluation with no exploration\n",
    "    if (episode + 1) % evaluation_interval == 0:\n",
    "        print(f\"Running evaluation at episode {episode+1}...\")\n",
    "        eval_rewards = []\n",
    "        \n",
    "        # Run multiple evaluation episodes\n",
    "        for eval_ep in range(5):\n",
    "            eval_obs, _ = env.reset()\n",
    "            eval_reward = 0\n",
    "            agent.reset()\n",
    "            \n",
    "            for _ in range(max_timesteps):\n",
    "                eval_action = agent.sample_action(eval_obs, deterministic=True)\n",
    "                eval_obs, eval_r, eval_term, eval_trunc, _ = env.step(eval_action)\n",
    "                eval_reward += eval_r\n",
    "                \n",
    "                if eval_term or eval_trunc:\n",
    "                    break\n",
    "                    \n",
    "            eval_rewards.append(eval_reward)\n",
    "        \n",
    "        avg_eval_reward = np.mean(eval_rewards)\n",
    "        print(f\"Evaluation complete - Avg reward over 5 episodes: {avg_eval_reward:.2f}\")\n",
    "\n",
    "# End of training\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in {total_time/60:.2f} minutes\")\n",
    "print(f\"Best average reward: {best_avg_reward:.2f}\")\n",
    "\n",
    "# Final evaluation\n",
    "# print(\"Running final evaluation...\")\n",
    "# final_eval_rewards = []\n",
    "# env.video = True  # Record final evaluation\n",
    "\n",
    "# for eval_ep in range(10):\n",
    "#     eval_obs, _ = env.reset()\n",
    "#     eval_reward = 0\n",
    "#     agent.reset()\n",
    "    \n",
    "#     for _ in range(max_timesteps):\n",
    "#         eval_action = agent.sample_action(eval_obs, deterministic=True)\n",
    "#         eval_obs, eval_r, eval_term, eval_trunc, _ = env.step(eval_action)\n",
    "#         eval_reward += eval_r\n",
    "        \n",
    "#         if eval_term or eval_trunc:\n",
    "#             break\n",
    "            \n",
    "#     final_eval_rewards.append(eval_reward)\n",
    "\n",
    "# final_avg_reward = np.mean(final_eval_rewards)\n",
    "# print(f\"Final evaluation - Avg reward over 10 episodes: {final_avg_reward:.2f}\")\n",
    "\n",
    "# Write log file\n",
    "env.write_log(folder=metrics_dir, file=\"agent-training-log.txt\")\n",
    "\n",
    "# Save final plot of complete training history\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(training_stats['avg_rewards'])\n",
    "plt.title('Average Reward')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Reward (last 100 episodes)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(training_stats['policy_losses'], label='Policy Loss')\n",
    "plt.plot(training_stats['value_losses'], label='Value Loss')\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(training_stats['episode_lengths'])\n",
    "plt.title('Episode Lengths')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Steps')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(training_stats['learning_rates'])\n",
    "plt.title('Learning Rate')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"complete_training_history.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save final metrics summary as JSON\n",
    "summary = {\n",
    "    'total_episodes': episode + 1,\n",
    "    'max_episodes': max_episodes,\n",
    "    'early_stopped': patience_counter >= early_stop_patience,\n",
    "    'training_duration_seconds': time.time() - start_time,\n",
    "    'final_avg_reward': final_avg_reward,\n",
    "    'best_avg_reward': best_avg_reward,\n",
    "    'final_learning_rate': agent.learning_rate,\n",
    "    'final_action_std': agent.action_std,\n",
    "    'best_model_path': os.path.join(checkpoint_dir, \"agent_best.pt\"),\n",
    "    'final_model_path': os.path.join(checkpoint_dir, f\"agent_checkpoint_ep{episode+1}.pt\"),\n",
    "    'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "with open(os.path.join(metrics_dir, \"training_summary.json\"), 'w') as f:\n",
    "    json.dump(summary, f, indent=4)\n",
    "\n",
    "# Generate a training report in markdown\n",
    "with open(os.path.join(metrics_dir, \"training_report.md\"), 'w') as f:\n",
    "    f.write(f\"# Bipedal Walker Training Report\\n\\n\")\n",
    "    f.write(f\"Generated on: {summary['timestamp']}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"## Training Summary\\n\\n\")\n",
    "    f.write(f\"- Total episodes: {summary['total_episodes']} / {summary['max_episodes']}\\n\")\n",
    "    f.write(f\"- Early stopping: {'Yes' if summary['early_stopped'] else 'No'}\\n\")\n",
    "    f.write(f\"- Training duration: {summary['training_duration_seconds']/60:.2f} minutes\\n\")\n",
    "    f.write(f\"- Final average reward: {summary['final_avg_reward']:.2f}\\n\")\n",
    "    f.write(f\"- Best average reward: {summary['best_avg_reward']:.2f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"## Hyperparameters\\n\\n\")\n",
    "    f.write(f\"- Initial learning rate: {initial_lr}\\n\")\n",
    "    f.write(f\"- Final learning rate: {summary['final_learning_rate']}\\n\")\n",
    "    f.write(f\"- Initial action STD: {agent.init_action_std}\\n\")\n",
    "    f.write(f\"- Final action STD: {summary['final_action_std']}\\n\")\n",
    "    f.write(f\"- Gamma (discount factor): {agent.gamma}\\n\")\n",
    "    f.write(f\"- GAE lambda: {agent.gae_lambda}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"## Model Files\\n\\n\")\n",
    "    f.write(f\"- Best model: `{summary['best_model_path']}`\\n\")\n",
    "    f.write(f\"- Final model: `{summary['final_model_path']}`\\n\\n\")\n",
    "    \n",
    "    f.write(f\"## Performance Analysis\\n\\n\")\n",
    "    f.write(f\"![Complete Training History](plots/complete_training_history.png)\\n\\n\")\n",
    "    f.write(f\"![Latest Metrics](plots/latest_metrics.png)\\n\\n\")\n",
    "\n",
    "print(f\"Complete metrics saved to {metrics_dir} directory\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small demo with a predefined heuristic that is suboptimal and has no notion of balance (and is designed for the orignal BipedalWalker environment)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.envs.box2d.bipedal_walker import BipedalWalkerHeuristics\n",
    "\n",
    "env = rld.make(\n",
    "    \"rldurham/Walker\",\n",
    "    # \"BipedalWalker-v3\",\n",
    "    render_mode=\"human\",\n",
    "    # render_mode=\"rgb_array\",\n",
    "    hardcore=False,\n",
    "    # hardcore=True,\n",
    ")\n",
    "_, obs, info = rld.seed_everything(42, env)\n",
    "\n",
    "heuristics = BipedalWalkerHeuristics()\n",
    "\n",
    "act = heuristics.step_heuristic(obs)\n",
    "for _ in range(500):\n",
    "    obs, rew, terminated, truncated, info = env.step(act)\n",
    "    act = heuristics.step_heuristic(obs)\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "    if env.render_mode == \"rgb_array\":\n",
    "        rld.render(env, clear=True)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
