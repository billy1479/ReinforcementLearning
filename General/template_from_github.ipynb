{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTNU1mwGB1ZD"
      },
      "source": [
        "**Dependencies and setup**\n",
        "\n",
        "This can take a minute or so..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rA38jtUgtZsG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mUnable to lock directory /var/lib/apt/lists/\u001b[0m\n",
            "\u001b[1;33mW: \u001b[0mProblem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\u001b[0m\n",
            "\u001b[1;33mW: \u001b[0mProblem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: gym[box2d] in /home/billy/.local/lib/python3.10/site-packages (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /home/billy/.local/lib/python3.10/site-packages (from gym[box2d]) (2.2.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/billy/.local/lib/python3.10/site-packages (from gym[box2d]) (3.1.1)\n",
            "Requirement already satisfied: pyglet>=1.4.0 in /home/billy/.local/lib/python3.10/site-packages (from gym[box2d]) (2.1.2)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /home/billy/.local/lib/python3.10/site-packages (from gym[box2d]) (2.3.5)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pyvirtualdisplay in /home/billy/.local/lib/python3.10/site-packages (3.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: utils in /home/billy/.local/lib/python3.10/site-packages (1.0.2)\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Xvfb'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deque, namedtuple\n\u001b[1;32m     25\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m display \u001b[38;5;241m=\u001b[39m \u001b[43mDisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisible\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m display\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     29\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyvirtualdisplay/display.py:54\u001b[0m, in \u001b[0;36mDisplay.__init__\u001b[0;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, retries, extra_args, manage_global_env, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbgcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbgcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_xauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_xauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# check_startup=check_startup,\u001b[39;49;00m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanage_global_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanage_global_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyvirtualdisplay/xvfb.py:44\u001b[0m, in \u001b[0;36mXvfbDisplay.__init__\u001b[0;34m(self, size, color_depth, bgcolor, use_xauth, fbdir, dpi, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fbdir \u001b[38;5;241m=\u001b[39m fbdir\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dpi \u001b[38;5;241m=\u001b[39m dpi\n\u001b[0;32m---> 44\u001b[0m \u001b[43mAbstractDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPROGRAM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_xauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_xauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanage_global_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanage_global_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyvirtualdisplay/abstractdisplay.py:85\u001b[0m, in \u001b[0;36mAbstractDisplay.__init__\u001b[0;34m(self, program, use_xauth, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_wfd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retries_current \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 85\u001b[0m helptext \u001b[38;5;241m=\u001b[39m \u001b[43mget_helptext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_displayfd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-displayfd\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m helptext\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_displayfd:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyvirtualdisplay/util.py:13\u001b[0m, in \u001b[0;36mget_helptext\u001b[0;34m(program)\u001b[0m\n\u001b[1;32m      6\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [program, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-help\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# py3.7+\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# p = subprocess.run(cmd, capture_output=True)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# stderr = p.stderr\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# py3.6 also\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m _, stderr \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mcommunicate()\n\u001b[1;32m     21\u001b[0m helptext \u001b[38;5;241m=\u001b[39m stderr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
            "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Xvfb'"
          ]
        }
      ],
      "source": [
        "# the FORK implementation was based on https://github.com/honghaow/FORK\n",
        "# some parts of the model implementation have been taken from https://github.com/Rafael1s/Deep-Reinforcement-Learning-Algorithms/tree/master/BipedalWalkerHardcore-TD3-FORK\n",
        "\n",
        "!apt update\n",
        "!apt install -y xvfb\n",
        "!pip install 'gym[box2d]'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install utils\n",
        "\n",
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import copy\n",
        "import utils\n",
        "from gym.wrappers.record_video import RecordVideo\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as disp\n",
        "from collections import deque, namedtuple\n",
        "%matplotlib inline\n",
        "\n",
        "display = Display(visible=0,size=(600,600))\n",
        "display.start()\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "plot_interval = 10 # update the plot every N episodes\n",
        "video_every = 25 # videos can take a very long time to render so only do it every N episodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJHtclV_30Re"
      },
      "source": [
        "**Reinforcement learning agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9Y_qHhuQq7W"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(object):\n",
        "  def __init__(self, state_dim, action_dim, max_size=int(1e6)):\n",
        "    self.max_size = max_size\n",
        "    self.ptr = 0\n",
        "    self.size = 0\n",
        "\n",
        "    self.state = np.zeros((max_size, state_dim))\n",
        "    self.action = np.zeros((max_size, action_dim))\n",
        "    self.next_state = np.zeros((max_size, state_dim))\n",
        "    self.reward = np.zeros((max_size, 1))\n",
        "    self.done = np.zeros((max_size, 1))\n",
        "  \n",
        "  def push(self, state, action, next_state, reward, done):\n",
        "    self.state[self.ptr] = state\n",
        "    self.action[self.ptr] = action\n",
        "    self.next_state[self.ptr] = next_state\n",
        "    self.reward[self.ptr] = reward\n",
        "    self.done[self.ptr] = done\n",
        "\n",
        "    self.ptr = (self.ptr + 1) % self.max_size\n",
        "    self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    ind = np.random.randint(0,int(self.size), size=batch_size)\n",
        "    return (\n",
        "      torch.FloatTensor(self.state[ind]).to(device),\n",
        "      torch.FloatTensor(self.action[ind]).to(device),\n",
        "      torch.FloatTensor(self.next_state[ind]).to(device),\n",
        "      torch.FloatTensor(self.reward[ind]).to(device),\n",
        "      torch.FloatTensor(self.done[ind]).to(device)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jXNHP8_U-rn"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mActor\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_dim, action_dim, max_action):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Actor, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "class Actor(nn.Module):\n",
        "\n",
        "  def __init__(self, state_dim, action_dim, max_action):\n",
        "    super(Actor, self).__init__()\n",
        "    self.fc1 = nn.Linear(state_dim, 256)\n",
        "    self.fc2 = nn.Linear(256, 256)\n",
        "    self.fc3 = nn.Linear(256, action_dim)\n",
        "    self.max_action = max_action\n",
        "\n",
        "  def forward(self, state):\n",
        "    x = F.relu(self.fc1(state))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = torch.tanh(self.fc3(x))\n",
        "    return self.max_action * x\n",
        "\n",
        "\n",
        "class Critic(nn.Module):\n",
        "\n",
        "  def __init__(self, state_dim, action_dim):\n",
        "    super(Critic, self).__init__()\n",
        "    self.l1 = nn.Linear(state_dim + action_dim, 256)\n",
        "    self.l2 = nn.Linear(256, 256)\n",
        "    self.l3 = nn.Linear(256, 1)\n",
        "    self.l4 = nn.Linear(state_dim + action_dim, 256)\n",
        "    self.l5 = nn.Linear(256, 256)\n",
        "    self.l6 = nn.Linear(256, 1)\n",
        "\n",
        "  def forward(self, state, action):\n",
        "    x = torch.cat([state, action], 1)\n",
        "    q1 = F.relu(self.l1(x))\n",
        "    q1 = F.relu(self.l2(q1))\n",
        "    q2 = F.relu(self.l4(x))\n",
        "    q2 = F.relu(self.l5(q2))\n",
        "    return self.l3(q1), self.l6(q2)\n",
        "\n",
        "\n",
        "class Sys(nn.Module):\n",
        "\n",
        "  def __init__(self, state_dim, action_dim):\n",
        "    super(Sys, self).__init__()\n",
        "    self.l1 = nn.Linear(state_dim + action_dim, 400)\n",
        "    self.l2 = nn.Linear(400, 300)\n",
        "    self.l3 = nn.Linear(300, state_dim)\n",
        "\n",
        "  def forward(self, state, action):\n",
        "    x = torch.cat([state, action], 1)\n",
        "    predict = F.relu(self.l1(x))\n",
        "    predict = F.relu(self.l2(predict))\n",
        "    return self.l3(predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHx0mu0jwz5c"
      },
      "outputs": [],
      "source": [
        "class TD3(object):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      env,\n",
        "      state_dim,\n",
        "      action_dim,\n",
        "      max_action,\n",
        "      policy_noise = 0.1,\n",
        "      noise_clip = 0.5,\n",
        "      policy_freq = 2,\n",
        "      sys_weight = 0.5,\n",
        "      sys_threshold = 0.02,\n",
        "      tau = 0.005,\n",
        "      lr = 0.001,\n",
        "      gamma = 0.99\n",
        "      ):\n",
        "\n",
        "    self.env = env\n",
        "\n",
        "    self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
        "    self.actor_target = copy.deepcopy(self.actor)\n",
        "    self.actor_optimiser = torch.optim.Adam(self.actor.parameters(), lr=lr)\n",
        "\n",
        "    self.critic = Critic(state_dim, action_dim).to(device)\n",
        "    self.critic_target = copy.deepcopy(self.critic)\n",
        "    self.critic_optimiser = torch.optim.Adam(self.critic.parameters(), lr=lr)\n",
        "\n",
        "    self.sys = Sys(state_dim, action_dim).to(device)\n",
        "    self.sys_optimiser = torch.optim.Adam(self.sys.parameters(), lr=lr)\n",
        "    self.sys.apply(self.weights)\n",
        "    self.sys_loss = 0\n",
        "\n",
        "    self.upper = float(self.env.action_space.high[0])\n",
        "    self.lower = float(self.env.action_space.low[0])\n",
        "    self.obs_upper = float(self.env.observation_space.high[0])\n",
        "    self.obs_lower = float(self.env.observation_space.low[0])\n",
        "\n",
        "    self.max_action = max_action\n",
        "    self.policy_noise = policy_noise\n",
        "    self.noise_clip = noise_clip\n",
        "    self.policy_freq = policy_freq\n",
        "    self.sys_weight = sys_weight\n",
        "    self.sys_threshold = sys_threshold\n",
        "    self.tau = tau\n",
        "    self.gamma = gamma\n",
        "\n",
        "  def weights(self, layer):\n",
        "    if type(layer) == nn.Linear:\n",
        "      torch.nn.init.xavier_normal_(layer.weight)\n",
        "      layer.bias.data.fill_(0.001)\n",
        "  \n",
        "  def select_action(self, state):\n",
        "    state = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
        "    return self.actor(state).cpu().data.numpy().flatten()\n",
        "  \n",
        "  def train(self, replay_buffer, batch_size, train_steps):\n",
        "    for i in range(train_steps):\n",
        "\n",
        "      state, action, next_state, reward, done = replay_buffer.sample(batch_size)\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        noise = (\n",
        "            torch.randn_like(action) * self.policy_noise\n",
        "        ).clamp(-self.noise_clip, self.noise_clip)\n",
        "        next_action = (\n",
        "            self.actor_target(next_state) + noise\n",
        "        ).clamp(-self.max_action, self.max_action)\n",
        "        target_Q1, target_Q2 = self.critic_target(next_state, next_action)\n",
        "        target_Q = torch.min(target_Q1, target_Q2)\n",
        "        target_Q = reward + (1 - done) * self.gamma * target_Q\n",
        "\n",
        "      current_Q1, current_Q2 = self.critic(state, action)\n",
        "      loss_Q1 = F.mse_loss(current_Q1, target_Q)\n",
        "      loss_Q2 = F.mse_loss(current_Q2, target_Q)\n",
        "      critic_loss = loss_Q1 + loss_Q2\n",
        "      self.critic_optimiser.zero_grad()\n",
        "      critic_loss.backward()\n",
        "      self.critic_optimiser.step()\n",
        "\n",
        "      predict_next_state = self.sys(state, action).clamp(self.obs_lower, self.obs_upper)\n",
        "      sys_loss = F.smooth_l1_loss(predict_next_state, next_state.detach())\n",
        "\n",
        "      self.sys_optimiser.zero_grad()\n",
        "      sys_loss.backward()\n",
        "      self.sys_optimiser.step()\n",
        "      self.sys_loss = sys_loss.item()\n",
        "\n",
        "      s_flag = 1 if sys_loss.item() < self.sys_threshold else 0\n",
        "\n",
        "      if i % self.policy_freq == 0:\n",
        "        actor_loss_1,_ = self.critic_target(state, self.actor(state))\n",
        "        actor_loss_1 = actor_loss_1.mean()\n",
        "        actor_loss_1 = - actor_loss_1\n",
        "        if s_flag == 1:\n",
        "          p_next = self.sys(state, self.actor(state)).clamp(self.obs_lower, self.obs_upper)\n",
        "          p_actions = self.actor(p_next.detach()) * self.upper\n",
        "          actor_loss_2,_ = self.critic_target(p_next.detach(), p_actions)\n",
        "          actor_loss_2 = actor_loss_2.mean()\n",
        "          p_next_2 = self.sys(p_next.detach(), p_actions).clamp(self.obs_lower, self.obs_upper)\n",
        "          p_actions_2 = self.actor(p_next_2.detach()) * self.upper\n",
        "          actor_loss_3,_ = self.critic_target(p_next_2.detach(), p_actions_2)\n",
        "          actor_loss_3 = actor_loss_3.mean()\n",
        "          actor_loss = actor_loss_1 - (self.sys_weight * actor_loss_2) - (0.5 * self.sys_weight * actor_loss_3)\n",
        "        else:\n",
        "          actor_loss = actor_loss_1\n",
        "      \n",
        "        self.critic_optimiser.zero_grad()\n",
        "        self.sys_optimiser.zero_grad()\n",
        "\n",
        "        self.actor_optimiser.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        self.actor_optimiser.step()\n",
        "\n",
        "        for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
        "          target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
        "        for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
        "          target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEv4ZjXmyrHo"
      },
      "source": [
        "**Prepare the environment and wrap it to capture videos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Xrcek4hxDXl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "env = gym.make(\"BipedalWalker-v3\")\n",
        "# env = gym.make(\"Pendulum-v0\") # useful continuous environment for quick experiments\n",
        "# env = gym.make(\"BipedalWalkerHardcore-v3\") # a more advanced environment\n",
        "env = RecordVideo(env, \"./video\", episode_trigger=lambda ep_id: ep_id%video_every == 0)\n",
        "\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.shape[0]\n",
        "max_action = float(env.action_space.high[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUw4h980jfnu",
        "outputId": "231e5b4f-d443-4ff0-f028-9b8c77b8d14d"
      },
      "outputs": [],
      "source": [
        "print('The environment has {} observations and the agent can take {} actions'.format(state_dim, action_dim))\n",
        "print('The device is: {}'.format(device))\n",
        "\n",
        "\n",
        "if device.type != 'cpu': print('It\\'s recommended to train on the cpu for this')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDl6ViIDlVOk"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "env.reset(seed=seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "env.action_space.seed(seed)\n",
        "\n",
        "# logging variables\n",
        "batch_size = 100\n",
        "start_t = 0 # set to 10000 when testing the model on the hardcore environment\n",
        "expl_noise = 0.1\n",
        "total_t = 0\n",
        "ep_reward = 0\n",
        "avg_reward = 0\n",
        "reward_list = []\n",
        "plot_data = []\n",
        "log_f = open(\"agent-log.txt\",\"w+\")\n",
        "\n",
        "# initialise agent\n",
        "agent = TD3(env, state_dim, action_dim, max_action)\n",
        "replay_buffer = ReplayBuffer(state_dim, action_dim)\n",
        "max_episodes = 500\n",
        "max_timesteps = 2000\n",
        "\n",
        "for episode in range(1, max_episodes + 1):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  for t in range(1, max_timesteps + 1):\n",
        "    total_t += 1\n",
        "    if total_t < start_t:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      action = (\n",
        "          agent.select_action(np.array(state))\n",
        "          + np.random.normal(0, max_action * expl_noise, size = action_dim)\n",
        "      ).clip(-max_action, max_action)\n",
        "    \n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    replay_buffer.push(state, action, next_state, reward, done)\n",
        "    state = next_state\n",
        "\n",
        "    ep_reward += reward\n",
        "    avg_reward += reward\n",
        "\n",
        "    if (done or t >= max_timesteps):\n",
        "      agent.update_sys = 0\n",
        "      if total_t >= start_t:\n",
        "        agent.train(replay_buffer, batch_size, t)\n",
        "      reward_list.append(avg_reward)\n",
        "      break\n",
        "\n",
        "    total_t += 1\n",
        "\n",
        "  log_f.write('episode: {}, reward: {}\\n'.format(episode, ep_reward))\n",
        "  log_f.flush()\n",
        "  ep_reward = 0\n",
        "  avg_reward = 0\n",
        "\n",
        "  if episode % plot_interval == 0:\n",
        "    plot_data.append([episode, np.array(reward_list).mean(), np.array(reward_list).std()])\n",
        "    reward_list = []\n",
        "    # plt.rcParams['figure.dpi'] = 100\n",
        "    plt.plot([x[0] for x in plot_data], [x[1] for x in plot_data], '-', color='tab:grey')\n",
        "    plt.fill_between([x[0] for x in plot_data], [x[1]-x[2] for x in plot_data], [x[1]+x[2] for x in plot_data], alpha=0.2, color='tab:grey')\n",
        "    plt.xlabel('Episode number')\n",
        "    plt.ylabel('Episode reward')\n",
        "    plt.show()\n",
        "    disp.clear_output(wait=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "part2-agent-code",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
